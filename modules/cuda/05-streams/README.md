# Модуль 5 — Streams & Asynchrony

Цель модуля — научиться перекрывать (overlap) передачу данных **Host↔Device** и вычисления на GPU при помощи независимых потоков исполнения — *CUDA Streams*.

## Пример `stream_overlap.cu`

1. Данные разбиваются на 4 чанка (параметр `CHUNKS`).  
2. Для каждого чанка: асинхронная копия H2D → ядро SAXPY → асинхронная копия D2H выполняются в своём стриме.  
3. Пока Stream 0 вычисляет, Stream 1 уже копирует следующий чанк и т.д.

Команда вывода печатает объём данных, полное время и эффективную полосу пропускания.

### Сборка и запуск

```bash
cmake --build build --target stream_overlap -j$(nproc)
./build/stream_overlap         # 64 MB
./build/stream_overlap 256     # 256 MB
```

### Теория

• **Stream** — упорядоченная очередь операций, которые GPU исполняет последовательно внутри этого стрима, но между разными стримами операции могут перекрываться.  
• Операции считаются асинхронными, если:  
  – используют `cudaMemcpyAsync`, ядра <<<... , stream>>>  
  – источником/приёмником host-данных является **pinned memory**.

#### Графика перекрытия

```
Time →
S0: H2D | KERNEL | D2H
S1:     H2D | KERNEL | D2H
S2:          H2D | KERNEL | D2H
...
```

#### Практические советы
1. Выбирайте размер чанка так, чтобы H2D ≈ KERNEL ≈ D2H (баланс).  
2. Используйте не менее 2–3 стримов; на современных GPU оптимально 4–8.  
3. Профилируйте Nsight Systems: ищите «PCIe Busy» и перекрытие с «Active Warps».

## Задания
1. Измените `CHUNKS` и измерьте ускорение.  
2. Попробуйте `cudaHostRegister` вместо `cudaHostAlloc`.  
3. Вместо SAXPY вставьте более тяжёлое ядро (например, суммирование по элементам) и посмотрите, как меняется эффективность перекрытия. 